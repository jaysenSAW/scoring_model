{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be download from [kraggle](https://www.kaggle.com/c/home-credit-default-risk/data) or directly [here](https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/Parcours_data_scientist/Projet+-+Impl%C3%A9menter+un+mod%C3%A8le+de+scoring/Projet+Mise+en+prod+-+home-credit-default-risk.zip). The projet concern a scoring score about cease of payment. Interactif dashboards are also present to understand the parameters behind the algorithm and the reason behind a refusal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d39a7132f281da17d7b86b9520930459b97ffaa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from bokeh.plotting import output_notebook, figure, show\n",
    "from bokeh.models import ColumnDataSource, Div, Select, Button, ColorBar, CustomJS\n",
    "from bokeh.layouts import row, column, layout\n",
    "from bokeh.transform import cumsum, linear_cmap\n",
    "from bokeh.palettes import Blues8\n",
    "\n",
    "output_notebook()\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_IQ(dt, q1=0.25, q3=0.75, return_flag = False):\n",
    "    \"\"\"\n",
    "    Compute interquantile value and return number\n",
    "    of elements \n",
    "        * Above Q3 + 1.5*IQ\n",
    "        * Bellow Q1 - 1*5 IQ\n",
    "    Arguments:\n",
    "        _dt: dataFrame (pandas)\n",
    "        _q1: first quantile (default 0.25)\n",
    "        _q3: third quantile (default 0.75)\n",
    "    \"\"\"\n",
    "    q1 = dt.quantile(q1)\n",
    "    q3 = dt.quantile(q3)\n",
    "    IQ = q3-q1\n",
    "    count = dt[dt < q1 - 1.5* IQ ].count() \n",
    "    print(\"Element {0} bellow Q1 - 1.5 * IQ ({1:.2f})\".format(count, q1 - 1.5* IQ))\n",
    "    count = dt[dt > q3 + 1.5* IQ ].count() \n",
    "    print(\"Element {0} above Q3 + 1.5 * IQ ({1:.2f})\".format(count ,q3 + 1.5 * IQ))\n",
    "    if return_flag:\n",
    "        return q1 - 1.5* IQ, q3 + 1.5* IQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_IQ(dt, lab, q1=0.25, q3=0.75):\n",
    "    borne_inf, borne_sup = distance_IQ(dt[lab], q1=0.25, q3=0.75, return_flag = True)\n",
    "    if borne_inf - borne_sup == 0:\n",
    "        print(\"distance IQ = 0\")\n",
    "        return dt\n",
    "    if borne_inf is not None:\n",
    "        dt = dt[dt[lab] > borne_inf]\n",
    "    if borne_sup is not None:\n",
    "        dt = dt[dt[lab] < borne_sup]\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f03367d7920e1b56786cc07792239d30f252857c"
   },
   "source": [
    "# Load data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12f1580beba72f4d82b8300518804e1f6fd62755"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('application_test.csv')\n",
    "df_train = pd.read_csv('application_train.csv')\n",
    "df_bureau = pd.read_csv('bureau.csv')\n",
    "df_bureau_balance = pd.read_csv('bureau_balance.csv')\n",
    "df_credit_balance = pd.read_csv('credit_card_balance.csv')\n",
    "df_home_credit = pd.read_csv(\"HomeCredit_columns_description.csv\", encoding = \"ISO-8859-1\")\n",
    "df_installments_payments = pd.read_csv(\"installments_payments.csv\")\n",
    "df_POS_CASH_balance = pd.read_csv(\"POS_CASH_balance.csv\")\n",
    "df_previous_application = pd.read_csv(\"previous_application.csv\")\n",
    "df_sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.head(3)\n",
    "#This is the main table, broken into two files for Train (with TARGET) and Test (without TARGET).\n",
    "#Static data for all applications. One row represents one loan in our data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_train[[\"SK_ID_CURR\", \"TARGET\", \"NAME_CONTRACT_TYPE\", \n",
    "                      \"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\",\n",
    "                      \"CNT_CHILDREN\", \"AMT_INCOME_TOTAL\", \"AMT_CREDIT\", \n",
    "                      \"AMT_ANNUITY\", \"AMT_GOODS_PRICE\", \"NAME_INCOME_TYPE\",\n",
    "                       \"NAME_EDUCATION_TYPE\", \"NAME_FAMILY_STATUS\", \"NAME_HOUSING_TYPE\",\n",
    "                      \"DAYS_BIRTH\", \"DAYS_EMPLOYED\", \"OWN_CAR_AGE\",\n",
    "                      \"OCCUPATION_TYPE\", \"CNT_FAM_MEMBERS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"LANDAREA_MODE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"TARGET\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.hist(\"TARGET\", density=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OCCUPATION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train[\"OCCUPATION_TYPE\"].value_counts(normalize = True).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"OCCUPATION_TYPE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DAYS_EMPLOYED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"DAYS_EMPLOYED\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[data_train[\"DAYS_EMPLOYED\"] < 50000].hist(\"DAYS_EMPLOYED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[(data_train[\"DAYS_EMPLOYED\"] >0) & (data_train[\"DAYS_EMPLOYED\"] < 500000)].hist(\"DAYS_EMPLOYED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**300 000 jours correspond Ã  plus de 87 ans de travail**. On supprime les valeurs positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance_IQ(data_train[\"DAYS_EMPLOYED\"])\n",
    "data_train = clean_IQ(data_train, \"DAYS_EMPLOYED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.hist(\"DAYS_EMPLOYED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAME_CONTRACT_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"NAME_CONTRACT_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CODE_GENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"CODE_GENDER\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retire le genre indÃ©fini pour Ã©viter de futur biais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train[df_train[\"CODE_GENDER\"] != \"XNA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMT_INCOME_TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_INCOME_TOTAL\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.hist(\"AMT_INCOME_TOTAL\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"AMT_INCOME_TOTAL\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/4 des individus ont moins de 200 000 euros de revenu. Et un individu gagne plus de 10 millions de dolars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = clean_IQ(data_train, \"AMT_INCOME_TOTAL\")\n",
    "data_train.hist(\"AMT_INCOME_TOTAL\", bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMT_CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_CREDIT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.hist(\"AMT_CREDIT\", bins= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = clean_IQ(data_train, \"AMT_CREDIT\")\n",
    "data_train.hist(\"AMT_CREDIT\", bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMT_ANNUITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_ANNUITY\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.hist(\"AMT_ANNUITY\", bins= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMT_GOODS_PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_GOODS_PRICE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.hist(\"AMT_GOODS_PRICE\", bins= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMT_REQ_CREDIT_BUREAU_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_REQ_CREDIT_BUREAU_HOUR\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_REQ_CREDIT_BUREAU_DAY\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"FLAG_OWN_REALTY\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### good data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train =pd.get_dummies(data_train, columns=[\"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\", \"FLAG_OWN_CAR\", \n",
    "                                    \"FLAG_OWN_REALTY\", \"NAME_FAMILY_STATUS\", \"NAME_CONTRACT_TYPE\", \n",
    "                                    \"CODE_GENDER\", 'NAME_HOUSING_TYPE'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bureau.head(3)\n",
    "#All client's previous credits provided by other financial institutions that were reported to Credit Bureau (for clients who have a loan in our sample).\n",
    "#For every loan in our sample, there are as many rows as number of credits the client had in Credit Bureau before the application date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau = df_bureau[[\"SK_ID_CURR\", \"SK_ID_BUREAU\", \"CREDIT_ACTIVE\", \"CREDIT_CURRENCY\", \n",
    "                         \"DAYS_CREDIT\", \"CREDIT_DAY_OVERDUE\", \"DAYS_CREDIT_ENDDATE\", \n",
    "                         \"DAYS_ENDDATE_FACT\", \"AMT_CREDIT_MAX_OVERDUE\", \"CNT_CREDIT_PROLONG\", \n",
    "                         \"AMT_CREDIT_SUM\", \"AMT_CREDIT_SUM_DEBT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau[\"CREDIT_ACTIVE\"].value_counts(normalize = True).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"CREDIT_CURRENCY\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"CREDIT_DAY_OVERDUE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau[\"CREDIT_DAY_OVERDUE\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.hist(\"CREDIT_DAY_OVERDUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau = clean_IQ(good_bureau, \"CREDIT_DAY_OVERDUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somme des crÃ©dits et durÃ©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.hist(\"DAYS_CREDIT_ENDDATE\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau[\"DAYS_CREDIT_ENDDATE\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau = clean_IQ(good_bureau, \"DAYS_CREDIT_ENDDATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.hist(\"DAYS_CREDIT_ENDDATE\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.hist(\"AMT_CREDIT_SUM\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau = clean_IQ(good_bureau, \"AMT_CREDIT_SUM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.hist(\"AMT_CREDIT_SUM\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = good_bureau[\"AMT_CREDIT_SUM\"].to_numpy()\n",
    "x = good_bureau[\"DAYS_CREDIT_ENDDATE\"].to_numpy()\n",
    "plt.scatter(x, y, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"CREDIT_ACTIVE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "good_bureau[\"CREDIT_ACTIVE\"].value_counts()\n",
    "#keep only row whith recent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"CREDIT_CURRENCY\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "good_bureau[\"CREDIT_CURRENCY\"].value_counts()\n",
    "#keep only row whith recent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"DAYS_CREDIT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bureau.hist(\"DAYS_CREDIT\", bins = 50)\n",
    "#keep only row whith recent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"DAYS_CREDIT_ENDDATE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.hist(\"DAYS_CREDIT_ENDDATE\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"DAYS_ENDDATE_FACT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.hist(\"DAYS_ENDDATE_FACT\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_CREDIT_SUM_DEBT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.hist(\"AMT_CREDIT_SUM_DEBT\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau = pd.get_dummies(good_bureau, columns=[\"CREDIT_ACTIVE\", \"CREDIT_CURRENCY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bureau.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_CREDIT_SUM_DEBT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sous tableau informations des crÃ©dits en cours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_credit_active = good_bureau[good_bureau[\"CREDIT_ACTIVE_Active\"] == 1]\n",
    "bureau_credit_active = bureau_credit_active[[\"SK_ID_CURR\", \"AMT_CREDIT_MAX_OVERDUE\", \"CREDIT_ACTIVE_Active\",\n",
    "                                             \"AMT_CREDIT_SUM\", ]].groupby([\"SK_ID_CURR\"]).sum()\n",
    "#rename columns\n",
    "bureau_credit_active[\n",
    "    \"AMT_CREDIT_MAX_OVERDUE\"\n",
    "] = bureau_credit_active[\"AMT_CREDIT_MAX_OVERDUE\"]/bureau_credit_active[\"AMT_CREDIT_SUM\"]\n",
    "bureau_credit_active = bureau_credit_active.rename(columns={\"AMT_CREDIT_MAX_OVERDUE\": \"proportion_OVERDUE_active\",\n",
    "                                                            \"CREDIT_ACTIVE_Active\" : \"CREDIT_Active\",\n",
    "                                                            \"AMT_CREDIT_SUM\": \"AMT_CREDIT_SUM_active\"})\n",
    "bureau_credit_active = bureau_credit_active.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sous tableau informations des crÃ©dits fermÃ©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_credit_closed = good_bureau[good_bureau[\"CREDIT_ACTIVE_Closed\"] == 1]\n",
    "bureau_credit_closed = bureau_credit_closed[[\"SK_ID_CURR\", \"AMT_CREDIT_MAX_OVERDUE\", \"CREDIT_ACTIVE_Closed\",\n",
    "                                             \"AMT_CREDIT_SUM\"]].groupby([\"SK_ID_CURR\"]).sum()\n",
    "id_curr = bureau_credit_closed.index.to_numpy()\n",
    "#rename columns\n",
    "bureau_credit_closed[\n",
    "    \"AMT_CREDIT_MAX_OVERDUE\"\n",
    "] = bureau_credit_closed[\"AMT_CREDIT_MAX_OVERDUE\"]/bureau_credit_closed[\"AMT_CREDIT_SUM\"]\n",
    "bureau_credit_closed = bureau_credit_closed.rename(columns={\"AMT_CREDIT_MAX_OVERDUE\": \"proportion_OVERDUE_closed\",\n",
    "                                                            \"CREDIT_ACTIVE_Closed\" : \"CREDIT_closed\",\n",
    "                                                            \"AMT_CREDIT_SUM\": \"AMT_CREDIT_SUM_closed\"})\n",
    "bureau_credit_closed = bureau_credit_closed.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sous tableau informations des crÃ©dits vendus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bureau_credit_sold = good_bureau[good_bureau[\"CREDIT_ACTIVE_Sold\"] == 1]\n",
    "bureau_credit_sold = bureau_credit_sold[[\"SK_ID_CURR\", \"AMT_CREDIT_MAX_OVERDUE\", \"CREDIT_ACTIVE_Sold\",\n",
    "                                             \"AMT_CREDIT_SUM\"]].groupby([\"SK_ID_CURR\"]).sum()\n",
    "#rename columns\n",
    "bureau_credit_sold[\n",
    "    \"AMT_CREDIT_MAX_OVERDUE\"\n",
    "] = bureau_credit_sold[\"AMT_CREDIT_MAX_OVERDUE\"]/bureau_credit_sold[\"AMT_CREDIT_SUM\"]\n",
    "bureau_credit_sold = bureau_credit_sold.rename(columns={\"AMT_CREDIT_MAX_OVERDUE\": \"proportion_OVERDUE_sold\",\n",
    "                                                        \"CREDIT_ACTIVE_Sold\" : \"CREDIT_sold\",\n",
    "                                                        \"AMT_CREDIT_SUM\": \"AMT_CREDIT_SUM_sold\"})\n",
    "bureau_credit_sold = bureau_credit_sold.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sous tableau informations des mauvais crÃ©dits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_credit_bad_debt = good_bureau[good_bureau[\"CREDIT_ACTIVE_Bad debt\"] == 1]\n",
    "bureau_credit_bad_debt = bureau_credit_bad_debt[[\"SK_ID_CURR\", \"AMT_CREDIT_MAX_OVERDUE\", \"CREDIT_ACTIVE_Bad debt\",\n",
    "                                             \"AMT_CREDIT_SUM\"]].groupby([\"SK_ID_CURR\"]).sum()\n",
    "#rename columns\n",
    "bureau_credit_bad_debt[\n",
    "    \"AMT_CREDIT_MAX_OVERDUE\"\n",
    "    ] = bureau_credit_bad_debt[\"AMT_CREDIT_MAX_OVERDUE\"]/bureau_credit_bad_debt[\"AMT_CREDIT_SUM\"]\n",
    "bureau_credit_bad_debt = bureau_credit_bad_debt.rename(columns={\"AMT_CREDIT_MAX_OVERDUE\": \"proportion_OVERDUE_bad\",\n",
    "                                                                \"CREDIT_ACTIVE_Bad debt\" : \"CREDIT_bad\",\n",
    "                                                        \"AMT_CREDIT_SUM\": \"AMT_CREDIT_SUM_bad\"})\n",
    "bureau_credit_bad_debt = bureau_credit_bad_debt.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.merge(bureau_credit_active, on='SK_ID_CURR', how='left')\n",
    "data_train = data_train.merge(bureau_credit_sold, on='SK_ID_CURR', how='left')\n",
    "data_train = data_train.merge(bureau_credit_closed, on='SK_ID_CURR', how='left')\n",
    "data_train = data_train.merge(bureau_credit_bad_debt, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_train.columns[36:]:\n",
    "    data_train[col] = data_train[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion des crÃ©dits qui sont arrivÃ©s Ã  terme, mauvais et vendu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.CREDIT_sold = data_train.CREDIT_sold / (data_train.CREDIT_sold +  data_train.CREDIT_closed + data_train.CREDIT_bad)\n",
    "data_train.CREDIT_closed = data_train.CREDIT_closed / (data_train.CREDIT_sold +  data_train.CREDIT_closed + data_train.CREDIT_bad)\n",
    "data_train.CREDIT_bad = data_train.CREDIT_bad / (data_train.CREDIT_sold +  data_train.CREDIT_closed + data_train.CREDIT_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_CREDIT_MAX_OVERDUE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_CREDIT_SUM\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_CREDIT_SUM_DEBT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_credit_detail = good_bureau[[\"SK_ID_CURR\", \"CREDIT_DAY_OVERDUE\", \"DAYS_CREDIT_ENDDATE\",\n",
    "                \"AMT_CREDIT_MAX_OVERDUE\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bureau balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bureau_balance.head(3)\n",
    "#Monthly balances of previous credits in Credit Bureau.\n",
    "#This table has one row for each month of history of every previous credit reported to Credit Bureau â€“ i.e the table has \n",
    "#(#loans in sample * # of relative previous credits * # of months where we have some history observable for the previous credits) rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"MONTHS_BALANCE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"STATUS\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrÃ©dit balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_balance.head(3)\n",
    "#Monthly balance snapshots of previous credit cards that the applicant has with Home Credit.\n",
    "#This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans) related to loans in our sample â€“ i.e. the table has (#loans in sample * # of relative previous credit cards * # of months where we have some history observable for the previous credit card) rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_balance.hist(\"AMT_BALANCE\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_IQ(df_credit_balance[\"AMT_BALANCE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_CREDIT_LIMIT_ACTUAL\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_DRAWINGS_ATM_CURRENT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"NAME_CONTRACT_STATUS\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_balance[\"NAME_CONTRACT_STATUS\"].value_counts(normalize = True).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_PAYMENT_TOTAL_CURRENT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_TOTAL_RECEIVABLE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"MONTHS_BALANCE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_balance.hist(\"MONTHS_BALANCE\", bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are not update every month. Most are older than 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_BALANCE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_CREDIT_LIMIT_ACTUAL\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_DRAWINGS_CURRENT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_DRAWINGS_ATM_CURRENT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_balance[df_credit_balance[\"AMT_BALANCE\"] < 600000].hist(\"AMT_BALANCE\", bins = 50)\n",
    "#df_credit_balance.hist(\"AMT_BALANCE\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"CNT_INSTALMENT_MATURE_CUM\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_balance.hist(\"AMT_BALANCE\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_CREDIT_LIMIT_ACTUAL\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_DRAWINGS_ATM_CURRENT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_DRAWINGS_CURRENT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_DRAWINGS_OTHER_CURRENT\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_balance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_credit_balance = clean_IQ(df_credit_balance, \"AMT_BALANCE\")\n",
    "df_credit_balance.hist(\"AMT_BALANCE\", bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_credit_balance.groupby(['SK_ID_CURR','NAME_CONTRACT_STATUS']).sum().reset_index()[\n",
    "    [\"SK_ID_CURR\", \"NAME_CONTRACT_STATUS\", \"AMT_BALANCE\", \"AMT_CREDIT_LIMIT_ACTUAL\"]\n",
    "    ]\n",
    "tmp2 = pd.DataFrame({\"Ratio_Credit_limit\" : tmp[\"AMT_BALANCE\"]/tmp[\"AMT_CREDIT_LIMIT_ACTUAL\"]})\n",
    "good_balance = pd.concat([tmp[['SK_ID_CURR']], tmp2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_balance.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "good_balance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_home_credit.loc[df_home_credit[\"Row\"] == \"AMT_BALANCE\", \"Description\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_balance.head(15)\n",
    "#Monthly balance snapshots of previous credit cards that the applicant has with Home Credit.\n",
    "#This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans) related to loans in our sample â€“ i.e. the table has (#loans in sample * # of relative previous credit cards * # of months where we have some history observable for the previous credit card) rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home crÃ©dit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_home_credit.head(10)\n",
    "#explain label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installments payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installments_payments.head(3)\n",
    "#Repayment history for the previously disbursed credits in Home Credit related to the loans in our sample.\n",
    "#There is a) one row for every payment that was made plus b) one row each for missed payment.\n",
    "#One row is equivalent to one payment of one installment OR one installment corresponding to one payment \n",
    "#of one previous Home Credit credit related to loans in our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installments_payments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS CASH balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_POS_CASH_balance.head(3)\n",
    "#Monthly balance snapshots of previous POS (point of sales) and cash loans that the applicant had with Home Credit.\n",
    "#This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans)\n",
    "#related to loans in our sample â€“ i.e. the table has \n",
    "#(#loans in sample * # of relative previous credits * # of months in which we have some history observable for the previous credits) rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_POS_CASH_balance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_home_credit[142:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## previous_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous_application.head(3)\n",
    "#All previous applications for Home Credit loans of clients who have loans in our sample.\n",
    "#There is one row for each previous application related to loans in our data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous_application.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous_application.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c26e0e934bb3dac276f144700bc323e3ab473294"
   },
   "source": [
    "# 2. Interactive bar chart with text display block\n",
    "\n",
    "The first chart will display the sex (female or male) of Titanic survivors depending on the lifeboats which they boarded. For this purpose I will be using an interactive bar chart which will display the number of people when hovering over the bars. To make this chart more interactive, I will add an HTML content block that will display additional text information about the lifeboat survivors when one of the bars is selected.\n",
    "\n",
    "I start by creating a new DataFrame `df1` with the columns `Lifeboat` and `Sex`. Don't forget to set is as a copy to avoid `SettingWithCopyWarning` further down the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2872f9d0b94f2d4d8a534d420cb0887f3314db6e"
   },
   "outputs": [],
   "source": [
    "df1 = full[['Lifeboat', 'Sex']].copy()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df08060192a44b81673560fd2ad59bc63db61683"
   },
   "source": [
    "I filter out the entries that contain `NaN` or `?` in the column `Lifeboat` and remove the unnecessary symbols. Then I create dummy variables from the column `Sex` in order to count how many females/males were present in each lifeboat. The prefix and the separator of dummy variables are made empty to avoid long column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8bef7d0235788efdcb44026a5af6f1b34ca6a607"
   },
   "outputs": [],
   "source": [
    "df1 = df1[(df1.Lifeboat.notna()) & (df1.Lifeboat != '?')]\n",
    "\n",
    "df1.loc[df1.Lifeboat == '14?', 'Lifeboat'] = '14'\n",
    "df1.loc[df1.Lifeboat == '15?', 'Lifeboat'] = '15'\n",
    "df1.loc[df1.Lifeboat == 'A[64]', 'Lifeboat'] = 'A'\n",
    "\n",
    "df1 = pd.get_dummies(df1, columns=['Sex'], prefix='', prefix_sep='')\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "adb9f1249322ef3ce79905ef7bcabb7b10a7fe17"
   },
   "source": [
    "Then I group the rows according to the values in `Lifeboat` and sum up the number of females/males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95b58f2b621aaddb6f99c594358c41b5f21ef592"
   },
   "outputs": [],
   "source": [
    "df1 = df1.groupby('Lifeboat', as_index=False).sum()\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d5568c52a2e0bea7f1ead1deabc83a89064272f"
   },
   "source": [
    "I thought that it would be interesting to arrange lifeboats according to the order in which they were launched (taken from [Wikipedia](https://en.wikipedia.org/wiki/Lifeboats_of_the_RMS_Titanic))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e404a490dcb2c9d877bd44be553fffe6f1417b60"
   },
   "outputs": [],
   "source": [
    "order = ['7', '5', '3', '8', '1', '6', '16', '14', '12', '9',\n",
    "         '11', '13', '15', '2', '10', '4', 'C', 'D', 'B', 'A']\n",
    "df1 = df1.set_index('Lifeboat').reindex(order).reset_index()\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1112e83d67e95745031314dc7364c919ff03a41e"
   },
   "source": [
    "I add the columns `female_per` and `male_per` that correspond to the percentages of females/males (rounded to one decimal value), and the column `Side` that corresponds to the side of the ship from which the lifeboats were launched. Lifeboats with odd numbers were launched from the starboard side and lifeboats with even numbers from the port side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ad0eb71bb1a5f2b1ac67868560c3b4e2b6dbd32"
   },
   "outputs": [],
   "source": [
    "df1['female_per'] = df1['female'] / (df1['female'] + df1['male']) * 100\n",
    "df1['male_per'] = df1['male'] / (df1['female'] + df1['male']) * 100\n",
    "df1[['female_per', 'male_per']] = df1[['female_per', 'male_per']].round(1)\n",
    "\n",
    "lifeboat_odd = ['1', '3', '5', '7', '9', '11', '13', '15', 'A', 'C']\n",
    "df1.loc[df1.Lifeboat.isin(lifeboat_odd), 'Side'] = 'starboard'\n",
    "df1.loc[~df1.Lifeboat.isin(lifeboat_odd), 'Side'] = 'port'\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f5f5a022710251cba59e1490b70d4acd6e027de"
   },
   "source": [
    "Below is the code for the bar chart.\n",
    "\n",
    "In order to interact with data in Bokeh, it is recommended to use its own data object ColumnDataSource (CDS). CDS allows some very nice interactive features like linking, streaming, etc. (see more in the [Bokeh User Guide](https://bokeh.pydata.org/en/latest/docs/user_guide/data.html)). The Pandas DataFrame `df1` can be provided as input to create the CDS `s1`.\n",
    "\n",
    "The central part of a Bokeh graph is the figure object that can be conveniently created with the function `figure()`. Since the bar chart will be categorical, the list of lifeboats should be passed from the CDS `s1.data['Lifeboat']` to the parameter `x_range`. Note that the list of lifeboats doesn't necessarily have to come from the CDS but I prefer to use only the CDS after it has been initialized. The tools `hover` and `tap`are added to the figure. The parameter `tooltips='@$name'` says that the hover tooltip will show the number of females/males of each bar while hovering over them.\n",
    "\n",
    "Here I chose to create a stacked vertical bar chart and added the corresponding glyph `vbar_stack` to the figure `p1`. The numbers of females/males in the lifeboats are taken from `s1` that was defined earlier. Some parameters of `p1` (like axis labels, grid lines, legend location, etc.) are adjusted separately.\n",
    "\n",
    "I would also like to create an HTML content block that will display additional text information about the specific lifeboat when its corresponding bar is selected. For this purpose I can initialize the Div object `div1` that encloses its contents in the HTML tag `<div>`.\n",
    "\n",
    "The interaction between the figure `p1` and the object `div1` is specified by the method `js_on_event()` that executes `callback1` whenever the user clicks on a bar from the bar chart. `callback1` is a custom JavaScript object that brings additional interactivity. One could also use [Bokeh applications](https://bokeh.pydata.org/en/latest/docs/user_guide/embed.html) that only requires Python but I couldn't figure out how to run Bokeh applications within a Kaggle noteobook.\n",
    "\n",
    "To test the resulting bar chart, go ahead and click on one of the bars. ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "461d2cb7ee8720cf4658aeac39ea26f46c13bb82"
   },
   "outputs": [],
   "source": [
    "# Create the ColumnDataSource object \"s1\"\n",
    "s1 = ColumnDataSource(df1)\n",
    "\n",
    "# Create the figure object \"p1\"\n",
    "p1 = figure(title='Click on a column to display more information',\n",
    "            plot_width=500, plot_height=325, x_range = s1.data['Lifeboat'],\n",
    "            toolbar_location=None, tools=['hover', 'tap'], tooltips='@$name')\n",
    "\n",
    "# Add stacked vertical bars to \"p1\"\n",
    "p1.vbar_stack(['female', 'male'], x='Lifeboat', width=0.8, source=s1,\n",
    "              fill_color=['#66c2a5', '#fc8d62'], line_color=None, legend=['Female', 'Male'])\n",
    "\n",
    "# Change parameters of \"p1\"\n",
    "p1.title.align = 'center'\n",
    "p1.xaxis.axis_label = 'Lifeboat (in launch order)'\n",
    "p1.yaxis.axis_label = 'Count'\n",
    "p1.y_range.start = 0\n",
    "p1.x_range.range_padding = 0.05\n",
    "p1.xgrid.grid_line_color = None\n",
    "p1.legend.orientation = 'horizontal'\n",
    "p1.legend.location = 'top_left'\n",
    "\n",
    "# Create the Div object \"div1\"\n",
    "div1 = Div()\n",
    "\n",
    "# Create the custom JavaScript callback\n",
    "callback1 = CustomJS(args=dict(s1=s1, div1=div1), code='''\n",
    "    var ind = s1.selected.indices;\n",
    "    if (String(ind) != '') {\n",
    "        lifeboat = s1.data['Lifeboat'][ind];\n",
    "        female = s1.data['female'][ind];\n",
    "        male = s1.data['male'][ind];\n",
    "        female_per = s1.data['female_per'][ind];\n",
    "        male_per = s1.data['male_per'][ind];\n",
    "        side = s1.data['Side'][ind];\n",
    "        message = '<b>Lifeboat: ' + String(lifeboat) + ' (' + String(side) + ' side)' + '</b><br>Females: ' + String(female) + ' (' + String(female_per) +  '%)' + '<br>Males: ' + String(male) + ' (' + String(male_per) +  '%)' + '<br>Total: ' + String(female+male);\n",
    "        div1.text = message;\n",
    "    }\n",
    "    else {\n",
    "        div1.text = '';\n",
    "    }\n",
    "''')        \n",
    "\n",
    "# When tapping the plot \"p1\" execute the \"callback1\"\n",
    "p1.js_on_event('tap', callback1)\n",
    "\n",
    "# Display \"p1\" and \"div1\" as a row\n",
    "show(row(p1, div1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5603012d964317b56ab61ff6fca69a4290eb8ace"
   },
   "source": [
    "It's worth noting that the number of people on this bar chart is lower than the real numbers. This is because there were quite some crew members in the lifeboats who are not included in this passengers list.\n",
    "\n",
    "Another observation is that most of the lifeboats were not filled to their maximum capacity. The most striking examples is the lifeboat 1 that had only 12 people in it (5 passengers and 7 crew members) with its full capacity of 40 people! The reason behind it was that in the beginning many passengers didn't believe that Titanic would sink.\n",
    "\n",
    "One might also notice that the number of males in the lifeboats was very high especially in the lifeboats launched from the starboard side (odd numbers). In comparison, the loading crew on the port side was much stricter with the rule \"women and children first\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79679c544c098ceba106d90ae770937875352644"
   },
   "source": [
    "# 3. Interactive pie chart with dropdown menu\n",
    "\n",
    "The second chart will display distribution of classes among the Titanic survivors depending on the lifeboats. For this purpose I will be using the interactive pie chart and the dropdown menu with the list of all lifeboats. When a lifeboat number is selected in the dropdown menu, the pie chart should update the distribution of classes.\n",
    "\n",
    "I begin by creating a DataFrame `df2` with the columns `Lifeboat` and `Pclass`. Then I apply the same procedures for cleaning, creating dummy variables, grouping and reordering as in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d994c3fa56109b6402e6d21f27f6fe39e307321"
   },
   "outputs": [],
   "source": [
    "df2 = full[['Lifeboat', 'Pclass']].copy()\n",
    "\n",
    "df2 = df2[(df2.Lifeboat.notna()) & (df2.Lifeboat != '?')]\n",
    "\n",
    "df2.loc[df2.Lifeboat == '14?', 'Lifeboat'] = '14'\n",
    "df2.loc[df2.Lifeboat == '15?', 'Lifeboat'] = '15'\n",
    "df2.loc[df2.Lifeboat == 'A[64]', 'Lifeboat'] = 'A'\n",
    "\n",
    "df2 = pd.get_dummies(df2, columns=['Pclass'], prefix='', prefix_sep='')\n",
    "\n",
    "df2 = df2.groupby('Lifeboat', as_index=False).sum()\n",
    "\n",
    "order = ['7', '5', '3', '8', '1', '6', '16', '14', '12', '9',\n",
    "         '11', '13', '15', '2', '10', '4', 'C', 'D', 'B', 'A']\n",
    "df2 = df2.set_index('Lifeboat').reindex(order).reset_index()\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb7515f2c357383bf78c606df9dfdabae51c875d"
   },
   "source": [
    "Instead of the amount of people per class I would prefer to see their percentage per class in a certain lifeboat. Therefore, I add columns `1_per`, `2_per`, `3_per` that indicate percentages of the corresponding classes.\n",
    "\n",
    "For a pie chart I will need to specify the angles (in radians) for each of the sectors. These angles are added as columns `1_ang`, `2_ang`, `3_ang` and can be easily obtained from the percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f85487d3284b8630e09b2a9cc3534a3581a6d237"
   },
   "outputs": [],
   "source": [
    "df2['1_per'] = df2['1'] / (df2['1'] + df2['2'] + df2['3']) * 100\n",
    "df2['2_per'] = df2['2'] / (df2['1'] + df2['2'] + df2['3']) * 100\n",
    "df2['3_per'] = df2['3'] / (df2['1'] + df2['2'] + df2['3']) * 100\n",
    "\n",
    "\n",
    "df2['1_ang'] = df2['1_per'] / 100 * 2 * np.pi\n",
    "df2['2_ang'] = df2['2_per'] / 100 * 2 * np.pi\n",
    "df2['3_ang'] = df2['3_per'] / 100 * 2 * np.pi\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "814b243248cfbece74b66f548b100c574f61d128"
   },
   "source": [
    "Notice that `df2` contains percentages and angles for all lifeboats. On the pie chart, however, I can only display the distribution of classes for one lifeboat. Therefore, a separate DataFrame `df2_plot` like the one below is needed for plotting. The percentages and angles will be passed from `df2` to `df2_plot` when a particular lifeboat is selected from the dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "248c5b5e045028fced7204a3301788251e3968ce"
   },
   "outputs": [],
   "source": [
    "df2_plot=pd.DataFrame({'class': ['Class 1', 'Class 2', 'Class 3'],\n",
    "                       'percent': [float('nan'), float('nan'), float('nan')],\n",
    "                       'angle': [float('nan'), float('nan'), float('nan')],\n",
    "                       'color': ['#c9d9d3', '#718dbf', '#e84d60']})\n",
    "df2_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d498104c05afdd89956c730df461bc5287d48944"
   },
   "source": [
    "Below is the code for the pie chart.\n",
    "\n",
    "Just like in the case of the bar chart, first I create the ColumnDataSource (CDS) objects. Here, however, two CDS `s2` and `s2_plot` are needed. `s2` will be used to store the percentages and angles for all lifeboats while `s2_plot` will contain information for only one lifeboat that is plotted at the moment. `s2` will be also used to update `s2_plot` when a different lifeboat is selected from the dropdown menu.\n",
    "\n",
    "During the initalization of the Figure object `p2` I slightly adjusted the `y_range` so that the legend doesn't cover the pie chart itself. I also changed the parameter `tooltips` to show the percentages rounded to one decimal digit when hovering over the sectors.\n",
    "\n",
    "The pie chart is created by adding circular sectors using the glyph `wedge()`. Its parameters `start_angle` and `end_angle` are easily calculated from the sector angles using the Bokeh function `cumsum()`.\n",
    "\n",
    "The dropdown menu is added with the Select object along with the options list. When the user chooses a different value from the dropdown menu, the method `js_on_change()` will execute the `callback2`. It checks if the value in the dropdown menu is not `Please choose...` and then updates `s2_plot` with the information from `s2` for the corresponding lifeboat. Note that `cb_obj` is the built-in Bokeh variable to store the value of the selected option when callbacks are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ccc66cf4507d6618be6ec5a9762db3d97eff3d4b"
   },
   "outputs": [],
   "source": [
    "# Create the ColumnDataSource objects \"s2\" and \"s2_plot\"\n",
    "s2 = ColumnDataSource(df2)\n",
    "s2_plot = ColumnDataSource(df2_plot)\n",
    "\n",
    "# Create the Figure object \"p2\"\n",
    "p2 = figure(plot_width=275, plot_height=350, y_range=(-0.5, 0.7),\n",
    "            toolbar_location=None, tools=['hover'], tooltips='@percent{0.0}%')\n",
    "\n",
    "# Add circular sectors to \"p2\"\n",
    "p2.wedge(x=0, y=0, radius=0.8, source=s2_plot,\n",
    "         start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "         fill_color='color', line_color=None, legend='class')\n",
    "\n",
    "# Change parameters of \"p2\"\n",
    "p2.axis.visible = False\n",
    "p2.grid.grid_line_color = None\n",
    "p2.legend.orientation = 'horizontal'\n",
    "p2.legend.location = 'top_center'\n",
    "\n",
    "# Create the custom JavaScript callback\n",
    "callback2 = CustomJS(args=dict(s2=s2, s2_plot=s2_plot), code='''\n",
    "    var ang = ['1_ang', '2_ang', '3_ang'];\n",
    "    var per = ['1_per', '2_per', '3_per'];\n",
    "    if (cb_obj.value != 'Please choose...') {\n",
    "        var boat = s2.data['Lifeboat'];\n",
    "        var ind = boat.indexOf(cb_obj.value);\n",
    "        for (var i = 0; i < ang.length; i++) {\n",
    "            s2_plot.data['angle'][i] = s2.data[ang[i]][ind];\n",
    "            s2_plot.data['percent'][i] = s2.data[per[i]][ind];\n",
    "        }\n",
    "    }\n",
    "    else {\n",
    "        for (var i = 0; i < ang.length; i++) {\n",
    "            s2_plot.data['angle'][i] = undefined;\n",
    "            s2_plot.data['percent'][i] = undefined;\n",
    "        }\n",
    "\n",
    "    }\n",
    "    s2_plot.change.emit();\n",
    "''')\n",
    "\n",
    "# When changing the value of the dropdown menu execute \"callback2\"\n",
    "options = ['Please choose...'] + list(s2.data['Lifeboat'])\n",
    "select = Select(title='Lifeboat (in launch order)', value=options[0], options=options)\n",
    "select.js_on_change('value', callback2)\n",
    "\n",
    "# Display \"select\" and \"p2\" as a column\n",
    "show(column(select, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eac0edd9b0d4d70fc9bcef5d2e33fd440dfce6be"
   },
   "source": [
    "Notice that first 6 lifeboats were almost exclusively filled with the passengers from the 1st class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66db209f9d48eb600af331fa6d7e26c14aa5da40"
   },
   "source": [
    "# 4. Choropleth map with reset button\n",
    "\n",
    "The third chart will display home countries of the Titanic survivors depending on the lifeboats. For this purpose I will be using a choropleth map and will do it in two steps. During the first step, I will import the countries coordinates and plot their boundaries. During the second step, I will fill in the shapes of the obtained countries with the numbers of people from these countries depending on the lifeboats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e7fe02e7f592999f0305aecfa70caebc2c9cd285"
   },
   "source": [
    "## 4.1. Plotting countries boundaries\n",
    "\n",
    "To import the coordinates of the countries boundaries, one can use the [Natural Earth map datasets](https://github.com/nvkelso/natural-earth-vector). Geopandas can easily import a GeoJSON file and returns a GeoDataFrame. The latter is very similar to a Pandas DataFrame, however, it has additional methods that are useful for handling geospatial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0a00fa3fa3cce66fcc7b92238ffa99d98569b2a"
   },
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/geojson/ne_110m_admin_0_countries.geojson')\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "464eab7c31de727dd18982b07e51c967c9cd29a0"
   },
   "source": [
    "Let's remove Antarctica from `gdf` since nobody lives there and it occupies a lot of space on the plot (especially in the equirectangular projection). Usingt the Geopandas method `plot()` I quickly check that Antarctica was indeed removed from `gdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "848533f1636c8c3ceba8da097e6522bc1ff2197e"
   },
   "outputs": [],
   "source": [
    "gdf = gdf[gdf.NAME != 'Antarctica']\n",
    "gdf.plot(figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7ed6a1ca92e87bf467ddd37ed21ea7629c2b699"
   },
   "source": [
    "The coordinates of the countries boundaries are stored in the column `geometry` as Polygon or MultiPolygon objects. When using the method `boundary` these objects return LineString and MultiLineString objects respectively.  The coordinates of a LineString object can be directly accessed using the method `xy`. The coordinates of the MultiLineString object need, however, to be extracted separately for every line. Therefore, the LineString and MultiLineString objects should be treated differently. Note that the boundary coordinates for Bokeh should be 3-times nested lists in order to plot them as multiple multipolygons. This complicated structure allows to distinguish multipolygons from each other, individual polygons inside a multipolygon and holes inside an individual polygon. One should keep this structure in mind when extracting the coordinates and add nested lists where necessary.\n",
    "\n",
    "Finally, I create a DataFrame `df3_plot` that contains countries names, x-y coordinates of their boundaries and a counter for the number of people. For this test chart I fill the counter with `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5365610232db6a7e25f2694e3cac417f0987c8c"
   },
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for obj in gdf.geometry.boundary:\n",
    "    if obj.type == 'LineString':\n",
    "        obj_x, obj_y = obj.xy\n",
    "        xs.append([[list(obj_x)]])\n",
    "        ys.append([[list(obj_y)]])\n",
    "    elif obj.type == 'MultiLineString':\n",
    "        obj_x = []\n",
    "        obj_y = []\n",
    "        for line in obj:\n",
    "            line_x, line_y = line.xy\n",
    "            obj_x.append([list(line_x)])\n",
    "            obj_y.append([list(line_y)])\n",
    "        xs.append(obj_x)\n",
    "        ys.append(obj_y)\n",
    "\n",
    "country = gdf['NAME'].values        \n",
    "\n",
    "df3_plot = pd.DataFrame({'country': country, 'xs': xs, 'ys': ys, 'count': float('nan')})\n",
    "\n",
    "df3_plot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c251bb648d68d7bdc21650c2a968a3038f5a87d0"
   },
   "source": [
    "Below is the code for test choropleth map that plots only countries boundaries.\n",
    "\n",
    "In addition to the `hover` tool, I include `pan` and `wheel_zoom` to easily navigate the map. The hover tooltip is set to display the country name.\n",
    "\n",
    "For plotting countries boundaries I use the Bokeh glyph `multi_polygons` that takes countries coordinates from `s3_plot`.\n",
    "\n",
    "To reset the map view, I add a button that executes `callback3_test` when clicking on it. The reset of the chart is also possible using the tool `reset` from the toolbar but I decided not to include the whole toolbar just for one button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0dffff640cd749608f3e208493f95349ea9b10ae"
   },
   "outputs": [],
   "source": [
    "# Create the ColumnDataSource object \"s3_plot\"\n",
    "s3_plot = ColumnDataSource(df3_plot)\n",
    "\n",
    "# Create the Figure object \"p3_test\"\n",
    "p3_test = figure(plot_width=775, plot_height=350,\n",
    "                 toolbar_location=None, tools=['hover', 'pan', 'wheel_zoom'],\n",
    "                 active_scroll='wheel_zoom', tooltips='@country')\n",
    "\n",
    "# Add multipolygons to \"p3_test\"\n",
    "p3_test.multi_polygons(xs='xs', ys='ys', fill_color='count', source=s3_plot)\n",
    "\n",
    "# Change parameters of \"p3_test\"\n",
    "p3_test.axis.visible = False\n",
    "p3_test.grid.grid_line_color = None\n",
    "\n",
    "# Create the custom JavaScript callback\n",
    "callback3_test = CustomJS(args=dict(p3_test=p3_test), code='''\n",
    "    p3_test.reset.emit();\n",
    "''')    \n",
    "\n",
    "# When clicking on the button execute \"callback3_test\"\n",
    "button = Button(label='Reset view')\n",
    "button.js_on_click(callback3_test)\n",
    "\n",
    "# Display \"p3_test\" and \"button\" as a column\n",
    "show(column(p3_test, button))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "845643849e2fe8de6250583e6be5f2256f3a198f"
   },
   "source": [
    "## 4.2. Filling in countries shapes\n",
    "\n",
    "To fill in countries shapes I need find the number of people for each country in lifeboats. This information can be extracted from the Titanic extended dataset. I begin by creating the DataFrame `df3` with the columns `Lifeboat` and `Hometown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ca9dcd8f1f01a3206d3200628fe52516ce77c09"
   },
   "outputs": [],
   "source": [
    "df3 = full[['Lifeboat', 'Hometown']].copy()\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e2bb2ea8720f2de5d81b9b5d268148c2a7c274e4"
   },
   "source": [
    "I extract home countries using regular expressions with matched groups. Then I remove the column `Hometown` since it is not needed anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e0cb5c12f5fdde314e504b6fb3f388c509ae9f6"
   },
   "outputs": [],
   "source": [
    "temp = df3.Hometown.str.extract(r'(?P<Town>.*)\\, (?P<Country>.*$)')\n",
    "df3['Home_country'] = temp['Country']\n",
    "df3 = df3.drop('Hometown', axis=1, errors='ignore')\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "13b25c55e8b0840214b125bed314621884933553"
   },
   "source": [
    "Afterwards I apply the same procedure to remove missing values and clean the values as in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ae22189da7b91d4eb1395d80470748807543740"
   },
   "outputs": [],
   "source": [
    "df3 = df3[(df3.Lifeboat.notna()) & (df3.Lifeboat != '?')]\n",
    "\n",
    "df3.loc[df3.Lifeboat == '14?', 'Lifeboat'] = '14'\n",
    "df3.loc[df3.Lifeboat == '15?', 'Lifeboat'] = '15'\n",
    "df3.loc[df3.Lifeboat == 'A[64]', 'Lifeboat'] = 'A'\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5702d2f08efec5d20ee48fbe9e29595232e00147"
   },
   "source": [
    "Note that some countries in `df3` are spelled as abbreviations (for example, \"US\" or \"UK) or have references (for example, \"UK[note 3]\"), or don't exist anymore (for example, \"Russian Empire\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72c5287bf9199f1af2ba56d295e2bb1d63354a7c"
   },
   "outputs": [],
   "source": [
    "df3.Home_country.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e63b6c81fe5ae69c6efab0be03f474b4dccb6bc"
   },
   "source": [
    "Therefore, the countries names need to be corrected according to their standard spelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1eeef3c373a9bffe2c6c87232dca5b0c934623d7"
   },
   "outputs": [],
   "source": [
    "to_replace = [('US', 'United States of America'), ('UK[note 3]', 'India'),\n",
    "              ('England', 'United Kingdom'), ('UK', 'United Kingdom'),\n",
    "              ('Channel Islands', 'United Kingdom'), ('Siam', 'Thailand'),\n",
    "              ('Syria[81]', 'Syria'), ('Scotland', 'United Kingdom'),\n",
    "              ('British India', 'India'), ('Ireland[note 1]', 'Ireland'),\n",
    "              ('Russian Empire', 'Russia'), ('Russian Empire[note 6]', 'Finland'),\n",
    "              ('Siam[note 5]', 'Thailand'), ('German Empire[note 2]', 'Germany'),\n",
    "              ('British India[note 3]', 'India')]\n",
    "\n",
    "for old, new in to_replace:\n",
    "    df3.loc[df3.Home_country == old, 'Home_country'] = new\n",
    "    \n",
    "df3.Home_country.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e7aa22af0a25380f388c97eca370ecaa6c855c38"
   },
   "source": [
    "Then I apply the rest of the familiar procedures to group the number of people from different countries for each lifeboat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ae22189da7b91d4eb1395d80470748807543740",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.get_dummies(df3, columns=['Home_country'], prefix='', prefix_sep='')\n",
    "\n",
    "df3 = df3.groupby('Lifeboat', as_index=False).sum()\n",
    "\n",
    "order = ['7', '5', '3', '8', '1', '6', '16', '14', '12', '9',\n",
    "         '11', '13', '15', '2', '10', '4', 'C', 'D', 'B', 'A']\n",
    "df3 = df3.set_index('Lifeboat').reindex(order).reset_index()\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d4f2990556f59f6e1e4b31e934e85c7443c4b7c"
   },
   "source": [
    "Note, however, that this is not the full list of countries that are displayed on the choropleth map. Therefore, I need to add the columns for all other countries from `d3_plot` and rearrange them in the same order as they appear in `d3_plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cae254bdf7be25f3b9ae31881c6331050ade19df"
   },
   "outputs": [],
   "source": [
    "country = df3_plot['country']\n",
    "diff = country[~country.isin(df3.columns)].values\n",
    "df3 = pd.concat([df3, pd.DataFrame(columns=diff)], axis=1).fillna(0)\n",
    "df3 = df3.loc[:, np.append(['Lifeboat'], country.values)]\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60fcfa51de6df566c515fdd384a28e32f5f766d0"
   },
   "source": [
    "Below is the code for the complete choropleth map.\n",
    "\n",
    "In addition to the test choropleth map, I created the colormap `cmap` that is used to fill in multipolygons. The upper limit of `cmap` is set to 1 so that all countries that have more than 1 person are highlighted with dark blue. In this way, it is easier to see smaller countries.\n",
    "\n",
    "I also adapted the hover tooltip to show the number of people after the country name.\n",
    "\n",
    "Finally, to choose a lifeboat, I have added the same dropdown menu as in the pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5300b1b7d97ffa19811600711aa152b729791194"
   },
   "outputs": [],
   "source": [
    "# Create the ColumnDataSource objects \"s3_plot\" and \"s3\"\n",
    "s3_plot = ColumnDataSource(df3_plot)\n",
    "s3 = ColumnDataSource(df3)\n",
    "\n",
    "# Reverse the palette and create a linear color map\n",
    "Blues8.reverse()\n",
    "cmap = linear_cmap('count', palette=Blues8, low=0, high=1)\n",
    "\n",
    "# Create the Figure object \"p3\"\n",
    "p3 = figure(plot_width=775, plot_height=350,\n",
    "            toolbar_location=None, tools=['hover', 'pan', 'wheel_zoom'],\n",
    "            active_scroll='wheel_zoom', tooltips='@country: @count')\n",
    "\n",
    "# Add multipolygons to \"p3\"\n",
    "p3.multi_polygons(xs='xs', ys='ys', fill_color=cmap, source=s3_plot)\n",
    "\n",
    "# Change parameters of \"p3\"\n",
    "p3.axis.visible = False\n",
    "p3.grid.grid_line_color = None\n",
    "\n",
    "# Create the custom JavaScript callbacks\n",
    "callback3_select = CustomJS(args=dict(s3=s3, s3_plot=s3_plot), code='''\n",
    "    var country = s3_plot.data['country'];\n",
    "    if (cb_obj.value != 'Please choose...') {\n",
    "        var boat = s3.data['Lifeboat'];\n",
    "        var ind = boat.indexOf(cb_obj.value);\n",
    "        for (i = 0; i < country.length; i++) {\n",
    "            s3_plot.data['count'][i] = s3.data[country[i]][ind];\n",
    "        }\n",
    "    }\n",
    "    else {\n",
    "        for (i = 0; i < country.length; i++) {\n",
    "            s3_plot.data['count'][i] = undefined;\n",
    "        }\n",
    "    }\n",
    "    s3_plot.change.emit();\n",
    "''')\n",
    "\n",
    "callback3_button = CustomJS(args=dict(p3=p3), code='''\n",
    "    p3.reset.emit();\n",
    "''')\n",
    "    \n",
    "# When changing the value of the dropdown menu execute \"callback3_select\"\n",
    "options = ['Please choose...'] + list(s3.data['Lifeboat'])\n",
    "select = Select(title='Lifeboat (in launch order)', value=options[0], options=options)\n",
    "select.js_on_change('value', callback3_select)\n",
    "\n",
    "# When clicking on the reset button execute \"callback3_button\"\n",
    "button = Button(label='Reset view')\n",
    "button.js_on_click(callback3_button)\n",
    "\n",
    "# Display \"select\", \"p3\", and \"button\" as a column\n",
    "show(column(select, p3, button))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "02e4961533db7922d884d6315dcfc41f1a89ccb3"
   },
   "source": [
    "# 5. Interactive dashboard of all three charts\n",
    "\n",
    "Now that we have all 3 charts, let's combine them in one dashboard. I don't have to initialize the charts again but can simply display them in a preferred layout.\n",
    "\n",
    "The only new element here is the `callback4` that updates the other two charts when a specific bar from the bar chart is tapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3b3ace50ece4606a802e6f08a900add88d8722a"
   },
   "outputs": [],
   "source": [
    "# Create the custom JavaScript callback\n",
    "callback4 = CustomJS(args=dict(s1=s1, s2=s2, s3=s3, s2_plot=s2_plot, s3_plot=s3_plot), code='''\n",
    "    var ind = s1.selected.indices;\n",
    "    var ang = ['1_ang', '2_ang', '3_ang'];\n",
    "    var per = ['1_per', '2_per', '3_per'];\n",
    "    var country = s3_plot.data['country'];\n",
    "    if (String(ind) != '') {\n",
    "        for (i = 0; i < ang.length; i++) {\n",
    "            s2_plot.data['angle'][i] = s2.data[ang[i]][ind];\n",
    "            s2_plot.data['percent'][i] = s2.data[per[i]][ind];\n",
    "        }\n",
    "        for (i = 0; i < country.length; i++) {\n",
    "            s3_plot.data['count'][i] = s3.data[country[i]][ind];\n",
    "        }\n",
    "    }\n",
    "    else {\n",
    "        for (i = 0; i < ang.length; i++) {\n",
    "            s2_plot.data['angle'][i] = undefined;\n",
    "            s2_plot.data['percent'][i] = undefined;\n",
    "        }\n",
    "        for (i = 0; i < country.length; i++) {\n",
    "            s3_plot.data['count'][i] = undefined;\n",
    "        }\n",
    "    }\n",
    "    s2_plot.change.emit();\n",
    "    s3_plot.change.emit();\n",
    "''')    \n",
    "    \n",
    "# When tapping the plot \"p1\" execute \"callback4\"\n",
    "p1.js_on_event('tap', callback4)\n",
    "\n",
    "# Display \"p1\",\"p2\", \"p3\" and \"button\" in the specified layout\n",
    "l = layout([[p1, p2], [p3], [button]])\n",
    "show(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60f38bff5b8571c9bd0d49ceaca2b1840acbde69"
   },
   "source": [
    "Thanks for **UPVOTING** this kernel! Trying to become a Kernels Master. ðŸ¤˜\n",
    "\n",
    "Check out my other cool projects:\n",
    "- [ðŸ’² Minimizing investment risk for high interest loans](https://www.kaggle.com/pavlofesenko/minimizing-investment-risk-for-high-interest-loans)\n",
    "- [ðŸŒ Extending Titanic dataset using Wikipedia](https://www.kaggle.com/pavlofesenko/extending-titanic-dataset-using-wikipedia)\n",
    "- [ðŸ‘ª Titanic extended dataset (Kaggle + Wikipedia)](https://www.kaggle.com/pavlofesenko/titanic-extended)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
